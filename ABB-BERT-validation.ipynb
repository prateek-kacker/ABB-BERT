{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "dict_cont = pickle.load(open('dict/dict_cont', 'rb'))\n",
    "dict_abb = pickle.load(open('dict/dict_abb', 'rb'))\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"-1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log Dir runs/20210514-141819\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calling BertTokenizer.from_pretrained() with the path to a single file or url is deprecated\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import math\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import datetime\n",
    "import string\n",
    "import glob\n",
    "import tensorflow as tf\n",
    "# \n",
    "current_time = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "log_dir = 'runs/' + current_time \n",
    "writer = tf.summary.create_file_writer(log_dir)\n",
    "print(\"Log Dir\",log_dir)\n",
    "load_model=True\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import CrossEntropyLoss, MSELoss\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, cohen_kappa_score, roc_auc_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "import transformers\n",
    "from transformers import BertTokenizer, BertModel, AdamW, BertConfig\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "\n",
    "from transformers.activations import gelu, gelu_new\n",
    "from transformers.file_utils import add_start_docstrings\n",
    "from transformers.modeling_utils import PreTrainedModel, prune_linear_layer\n",
    "\n",
    "\n",
    "import pickle\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "def rank_fn(logs):\n",
    "    a,b=logs.sort(1,True)\n",
    "    c=np.where(b.cpu().numpy()==0)\n",
    "    return c[1]\n",
    "\n",
    "\n",
    "\n",
    "def tokenize_sent_map_to_ids(sentence, MAX_LEN = 128 ):\n",
    "    # Tokenize all of the sentences and map the tokens to thier word IDs.\n",
    "    \n",
    "    '''a function that takes a dataframe df containing columns CONTENT and class for sentences and labels respectively.\n",
    "    returns input id's and attention mask '''\n",
    "    \n",
    "    input_ids = []\n",
    "    changed_input_ids = []\n",
    "    encoded_sent = tokenizer.encode(\n",
    "                        sentence,                      # Sentence to encode.\n",
    "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "                   )\n",
    "\n",
    "    input_ids.append(encoded_sent)\n",
    "\n",
    "    from keras.preprocessing.sequence import pad_sequences\n",
    "    input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", \n",
    "                              value=0, truncating=\"post\", padding=\"post\")\n",
    "\n",
    "    attention_masks = []\n",
    "    for sent in input_ids:\n",
    "        att_mask = [int(token_id > 0) for token_id in sent]\n",
    "        attention_masks.append(att_mask)\n",
    "\n",
    "    return torch.tensor(input_ids), torch.tensor(attention_masks)\n",
    "\n",
    "def tokenize_sent1_sent2_map_to_ids(sentence1,sentence2=[], MAX_LEN = 512 ):\n",
    "    # Tokenize all of the sentences and map the tokens to thier word IDs.\n",
    "    \n",
    "    '''a function that takes a dataframe df containing columns CONTENT and class for sentences and labels respectively.\n",
    "    returns input id's and attention mask '''\n",
    "    \n",
    "\n",
    "    input_ids = []\n",
    "    if len(sentence2)!=0:\n",
    "        for sent1,sent2 in zip(sentence1,sentence2):\n",
    "            encoded_sent = tokenizer.encode(\n",
    "                                str(sent1),                      # Sentence to encode.\n",
    "                                str(sent2),\n",
    "                                add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "                           )\n",
    "\n",
    "            input_ids.append(encoded_sent)\n",
    "    else:\n",
    "        for sent1 in sentence1:\n",
    "            encoded_sent = tokenizer.encode(\n",
    "                                str(sent1),                      # Sentence to encode.\n",
    "                                add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "                           )\n",
    "\n",
    "            input_ids.append(encoded_sent)\n",
    "        \n",
    "    max_len=max([len(sen) for sen in input_ids])\n",
    "    from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "    if max_len < MAX_LEN:\n",
    "        MAX_LEN=max_len\n",
    "        \n",
    "    input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", \n",
    "                              value=0, truncating=\"post\", padding=\"post\")\n",
    "\n",
    "    attention_masks = []\n",
    "    for sent in input_ids:\n",
    "        att_mask = [int(token_id > 0) for token_id in sent]\n",
    "        attention_masks.append(att_mask)\n",
    "\n",
    "    return torch.tensor(input_ids), torch.tensor(attention_masks)\n",
    "\n",
    "#### LOAD BERT Tokenizer\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('tokenizer.txt')\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "BERT_PRETRAINED_MODEL_ARCHIVE_MAP = {\n",
    "    \"bert-base-uncased\": \"https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin\",\n",
    "    \"bert-large-uncased\": \"https://cdn.huggingface.co/bert-large-uncased-pytorch_model.bin\",\n",
    "    \"bert-base-cased\": \"https://cdn.huggingface.co/bert-base-cased-pytorch_model.bin\",\n",
    "    \"bert-large-cased\": \"https://cdn.huggingface.co/bert-large-cased-pytorch_model.bin\",\n",
    "    \"bert-base-multilingual-uncased\": \"https://cdn.huggingface.co/bert-base-multilingual-uncased-pytorch_model.bin\",\n",
    "    \"bert-base-multilingual-cased\": \"https://cdn.huggingface.co/bert-base-multilingual-cased-pytorch_model.bin\",\n",
    "    \"bert-base-chinese\": \"https://cdn.huggingface.co/bert-base-chinese-pytorch_model.bin\",\n",
    "    \"bert-base-german-cased\": \"https://cdn.huggingface.co/bert-base-german-cased-pytorch_model.bin\",\n",
    "    \"bert-large-uncased-whole-word-masking\": \"https://cdn.huggingface.co/bert-large-uncased-whole-word-masking-pytorch_model.bin\",\n",
    "    \"bert-large-cased-whole-word-masking\": \"https://cdn.huggingface.co/bert-large-cased-whole-word-masking-pytorch_model.bin\",\n",
    "    \"bert-large-uncased-whole-word-masking-finetuned-squad\": \"https://cdn.huggingface.co/bert-large-uncased-whole-word-masking-finetuned-squad-pytorch_model.bin\",\n",
    "    \"bert-large-cased-whole-word-masking-finetuned-squad\": \"https://cdn.huggingface.co/bert-large-cased-whole-word-masking-finetuned-squad-pytorch_model.bin\",\n",
    "    \"bert-base-cased-finetuned-mrpc\": \"https://cdn.huggingface.co/bert-base-cased-finetuned-mrpc-pytorch_model.bin\",\n",
    "    \"bert-base-german-dbmdz-cased\": \"https://cdn.huggingface.co/bert-base-german-dbmdz-cased-pytorch_model.bin\",\n",
    "    \"bert-base-german-dbmdz-uncased\": \"https://cdn.huggingface.co/bert-base-german-dbmdz-uncased-pytorch_model.bin\",\n",
    "    \"bert-base-japanese\": \"https://cdn.huggingface.co/cl-tohoku/bert-base-japanese/pytorch_model.bin\",\n",
    "    \"bert-base-japanese-whole-word-masking\": \"https://cdn.huggingface.co/cl-tohoku/bert-base-japanese-whole-word-masking/pytorch_model.bin\",\n",
    "    \"bert-base-japanese-char\": \"https://cdn.huggingface.co/cl-tohoku/bert-base-japanese-char/pytorch_model.bin\",\n",
    "    \"bert-base-japanese-char-whole-word-masking\": \"https://cdn.huggingface.co/cl-tohoku/bert-base-japanese-char-whole-word-masking/pytorch_model.bin\",\n",
    "    \"bert-base-finnish-cased-v1\": \"https://cdn.huggingface.co/TurkuNLP/bert-base-finnish-cased-v1/pytorch_model.bin\",\n",
    "    \"bert-base-finnish-uncased-v1\": \"https://cdn.huggingface.co/TurkuNLP/bert-base-finnish-uncased-v1/pytorch_model.bin\",\n",
    "    \"bert-base-dutch-cased\": \"https://cdn.huggingface.co/wietsedv/bert-base-dutch-cased/pytorch_model.bin\",\n",
    "}\n",
    "\n",
    "\n",
    "def load_tf_weights_in_bert(model, config, tf_checkpoint_path):\n",
    "    \"\"\" Load tf checkpoints in a pytorch model.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        import re\n",
    "        import numpy as np\n",
    "        import tensorflow as tf\n",
    "    except ImportError:\n",
    "        logger.error(\n",
    "            \"Loading a TensorFlow model in PyTorch, requires TensorFlow to be installed. Please see \"\n",
    "            \"https://www.tensorflow.org/install/ for installation instructions.\"\n",
    "        )\n",
    "        raise\n",
    "    tf_path = os.path.abspath(tf_checkpoint_path)\n",
    "    logger.info(\"Converting TensorFlow checkpoint from {}\".format(tf_path))\n",
    "    # Load weights from TF model\n",
    "    init_vars = tf.train.list_variables(tf_path)\n",
    "    names = []\n",
    "    arrays = []\n",
    "    for name, shape in init_vars:\n",
    "        logger.info(\"Loading TF weight {} with shape {}\".format(name, shape))\n",
    "        array = tf.train.load_variable(tf_path, name)\n",
    "        names.append(name)\n",
    "        arrays.append(array)\n",
    "\n",
    "    for name, array in zip(names, arrays):\n",
    "        name = name.split(\"/\")\n",
    "        if any(\n",
    "            n in [\"adam_v\", \"adam_m\", \"AdamWeightDecayOptimizer\", \"AdamWeightDecayOptimizer_1\", \"global_step\"]\n",
    "            for n in name\n",
    "        ):\n",
    "            logger.info(\"Skipping {}\".format(\"/\".join(name)))\n",
    "            continue\n",
    "        pointer = model\n",
    "        for m_name in name:\n",
    "            if re.fullmatch(r\"[A-Za-z]+_\\d+\", m_name):\n",
    "                scope_names = re.split(r\"_(\\d+)\", m_name)\n",
    "            else:\n",
    "                scope_names = [m_name]\n",
    "            if scope_names[0] == \"kernel\" or scope_names[0] == \"gamma\":\n",
    "                pointer = getattr(pointer, \"weight\")\n",
    "            elif scope_names[0] == \"output_bias\" or scope_names[0] == \"beta\":\n",
    "                pointer = getattr(pointer, \"bias\")\n",
    "            elif scope_names[0] == \"output_weights\":\n",
    "                pointer = getattr(pointer, \"weight\")\n",
    "            elif scope_names[0] == \"squad\":\n",
    "                pointer = getattr(pointer, \"classifier\")\n",
    "            else:\n",
    "                try:\n",
    "                    pointer = getattr(pointer, scope_names[0])\n",
    "                except AttributeError:\n",
    "                    logger.info(\"Skipping {}\".format(\"/\".join(name)))\n",
    "                    continue\n",
    "            if len(scope_names) >= 2:\n",
    "                num = int(scope_names[1])\n",
    "                pointer = pointer[num]\n",
    "        if m_name[-11:] == \"_embeddings\":\n",
    "            pointer = getattr(pointer, \"weight\")\n",
    "        elif m_name == \"kernel\":\n",
    "            array = np.transpose(array)\n",
    "        try:\n",
    "            assert pointer.shape == array.shape\n",
    "        except AssertionError as e:\n",
    "            e.args += (pointer.shape, array.shape)\n",
    "            raise\n",
    "        logger.info(\"Initialize PyTorch weight {}\".format(name))\n",
    "        pointer.data = torch.from_numpy(array)\n",
    "    return model\n",
    "\n",
    "\n",
    "def mish(x):\n",
    "    return x * torch.tanh(nn.functional.softplus(x))\n",
    "\n",
    "\n",
    "ACT2FN = {\"gelu\": gelu, \"relu\": torch.nn.functional.relu, \"gelu_new\": gelu_new, \"mish\": mish}\n",
    "\n",
    "\n",
    "BertLayerNorm = torch.nn.LayerNorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification_notes: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification_notes from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification_notes from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification_notes were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['bert.embeddings.position_ids', 'classifier2.hidden.0.weight', 'classifier2.hidden.0.bias', 'classifier2.out.weight', 'classifier2.out.bias', 'personalization_layer.hidden.0.weight', 'personalization_layer.hidden.0.bias', 'personalization_layer.out.weight', 'personalization_layer.out.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class BertPreTrainedModel(PreTrainedModel):\n",
    "    \"\"\" An abstract class to handle weights initialization and\n",
    "        a simple interface for downloading and loading pretrained models.\n",
    "    \"\"\"\n",
    "\n",
    "    config_class = BertConfig\n",
    "    pretrained_model_archive_map = BERT_PRETRAINED_MODEL_ARCHIVE_MAP\n",
    "    load_tf_weights = load_tf_weights_in_bert\n",
    "    base_model_prefix = \"bert\"\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        \"\"\" Initialize the weights \"\"\"\n",
    "        if isinstance(module, (nn.Linear, nn.Embedding)):\n",
    "            # Slightly different from the TF version which uses truncated_normal for initialization\n",
    "            # cf https://github.com/pytorch/pytorch/pull/5617\n",
    "            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n",
    "        elif isinstance(module, BertLayerNorm):\n",
    "            module.bias.data.zero_()\n",
    "            module.weight.data.fill_(1.0)\n",
    "        if isinstance(module, nn.Linear) and module.bias is not None:\n",
    "            module.bias.data.zero_()\n",
    "\n",
    "\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "    \n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, h_size, out_size, num_hid_layers):\n",
    "        super(MLP, self).__init__()\n",
    "        self.hidden = nn.ModuleList()\n",
    "        for k in range(num_hid_layers):\n",
    "            self.hidden.append(nn.Linear(h_size, h_size)) \n",
    "        # Output layer\n",
    "        self.out = nn.Linear(h_size, out_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Feedforward\n",
    "        for layer in self.hidden:\n",
    "            x = F.relu(layer(x))\n",
    "            \n",
    "        output= self.out(x)\n",
    "\n",
    "        return output\n",
    "\n",
    "class MLP_1(nn.Module):\n",
    "    def __init__(self, h_size, out_size, num_hid_layers):\n",
    "        super(MLP_1, self).__init__()\n",
    "        self.hidden = nn.ModuleList()\n",
    "        for k in range(num_hid_layers):\n",
    "            self.hidden.append(nn.Linear(h_size, h_size)) \n",
    "        # Output layer\n",
    "        self.out = nn.Linear(h_size, out_size)\n",
    "    \n",
    "    def forward(self, x):            \n",
    "        output= self.out(x)\n",
    "        return output\n",
    "  \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class AdMSoftmaxLoss(nn.Module):\n",
    "\n",
    "    def __init__(self, in_features, out_features,m=.8, s = 30):\n",
    "        '''\n",
    "        AM Softmax Loss\n",
    "        '''\n",
    "        super(AdMSoftmaxLoss, self).__init__()\n",
    "        self.m = m\n",
    "        self.s = s\n",
    "\n",
    "    def forward(self, sentence, alternatives, labels):\n",
    "        '''\n",
    "        input shape (N, in_features)\n",
    "        '''\n",
    "\n",
    "\n",
    "        logits = torch.cosine_similarity(sentence,alternatives, dim = -1) \n",
    "\n",
    "        numerator = self.s *(torch.cosine_similarity(sentence,alternatives,dim=-1) - self.m * torch.tensor(labels).repeat(sentence.shape[0],1))\n",
    "\n",
    "        numerator=torch.exp(numerator)\n",
    "\n",
    "        denominator=torch.sum(numerator,1)\n",
    "        denominator=denominator.repeat((numerator.shape[1],1)).transpose(0,1)\n",
    "\n",
    "        loss=-torch.log(numerator/denominator)\n",
    "\n",
    "        return torch.mean(loss,1),numerator,logits\n",
    "    \n",
    "    \n",
    "class BertForSequenceClassification_notes(BertPreTrainedModel):\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        \n",
    "        self.num_labels = config.num_labels\n",
    "        self.bert = BertModel(config)\n",
    "        self.dropout = nn.Dropout(.1)\n",
    "        self.classifier2 = MLP_1(config.hidden_size,config.hidden_size,1)\n",
    "        self.init_weights()\n",
    "        self.hidden_size = config.hidden_size\n",
    "        self.personalization_layer = MLP_1(config.hidden_size,config.hidden_size,1)\n",
    "        \n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids=None,\n",
    "        input_ids_alt = None,\n",
    "        attention_mask=None,\n",
    "        attention_mask_alt = None, \n",
    "        token_type_ids=None,\n",
    "        position_ids=None,\n",
    "        head_mask=None,\n",
    "        inputs_embeds=None,\n",
    "        labels=None,\n",
    "        train = True,\n",
    "        index_of_abb = None,\n",
    "        num_of_options=5,\n",
    "        alt_batch=10,\n",
    "        all_options=False,\n",
    "        all_alt_input_ids=False,\n",
    "        all_abb_bert=False,\n",
    "        just_cls=False,\n",
    "        all_alt_input_ids_vectors=[],\n",
    "        all_alt_abb_bert_vectors=[]\n",
    "    ):\n",
    " \n",
    "\n",
    "        outputs_1 = self.bert(\n",
    "            input_ids = input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids,\n",
    "            position_ids=position_ids,\n",
    "            head_mask=head_mask,\n",
    "            inputs_embeds=inputs_embeds\n",
    "        )\n",
    "\n",
    "        if not just_cls:            \n",
    "            abb_indices = [l.item() for l in ((input_ids.flatten() == 1).nonzero()).flatten()]\n",
    "            abb_output = torch.stack([outputs_1[0][:,l,:] for l in abb_indices])\n",
    "            sent_int = abb_output\n",
    "            sent_int = self.dropout(sent_int)\n",
    "            sent_int2 = self.classifier2(sent_int)\n",
    "            sent_int2 = sent_int2.reshape((len(abb_indices),1,768))\n",
    "            sent=self.personalization_layer(sent_int2)\n",
    "        else:\n",
    "            sent_int =outputs_1[0][:,0,:]\n",
    "            sent_int = self.dropout(sent_int)\n",
    "            sent_int2 = self.classifier2(sent_int)\n",
    "            return sent_int2\n",
    "        \n",
    "        logits_list = []\n",
    "        if not all_options:\n",
    "            shapes_alts=input_ids_alt.shape\n",
    "            for alt_ids_index in range(0,shapes_alts[0],alt_batch):\n",
    "                outputs_2 = self.bert(\n",
    "                    input_ids = input_ids_alt[alt_ids_index:alt_ids_index+alt_batch,:],\n",
    "                    attention_mask = attention_mask_alt[alt_ids_index:alt_ids_index+alt_batch,:],\n",
    "                    token_type_ids=token_type_ids,\n",
    "                    position_ids=position_ids,\n",
    "                    head_mask=head_mask,\n",
    "                    inputs_embeds=inputs_embeds)\n",
    "                if alt_ids_index==0:\n",
    "                    cls_output=outputs_2[0][:,0,:]\n",
    "                else:\n",
    "                    cls_output=torch.cat((cls_output,outputs_2[0][:,0,:]),dim=0)\n",
    "\n",
    "\n",
    "            criteria = AdMSoftmaxLoss(self.hidden_size,self.hidden_size)\n",
    "            altx = torch.stack([cls_output[i*num_of_options:(i+1)*num_of_options] for i in range(len(abb_indices))])\n",
    "\n",
    "            altx = self.classifier2(altx)\n",
    "            loss_1,logits,logits_list_test = criteria(sent, altx, labels )\n",
    "\n",
    "            logits_list.append(logits_list_test)\n",
    "            loss = loss_1\n",
    "\n",
    "\n",
    "        elif all_alt_input_ids: # When input ids are present\n",
    "            logits_list = []\n",
    "            for (all_alt_input_ids_vector,all_attention_mask_alt),label in all_alt_input_ids_vectors:\n",
    "                shapes_alts=all_alt_input_ids_vector.shape\n",
    "                for alt_ids_index in range(0,shapes_alts[0],alt_batch):\n",
    "                    outputs_2 = self.bert(\n",
    "                        input_ids = all_alt_input_ids_vector[alt_ids_index:alt_ids_index+alt_batch,:],\n",
    "                        attention_mask = all_attention_mask_alt[alt_ids_index:alt_ids_index+alt_batch,:],\n",
    "                        token_type_ids=token_type_ids,\n",
    "                        position_ids=position_ids,\n",
    "                        head_mask=head_mask,\n",
    "                        inputs_embeds=inputs_embeds)\n",
    "                    if alt_ids_index==0:\n",
    "                        cls_output=outputs_2[0][:,0,:]\n",
    "                    else:\n",
    "                        cls_output=torch.cat((cls_output,outputs_2[0][:,0,:]),dim=0)\n",
    "\n",
    "                criteria = AdMSoftmaxLoss(self.hidden_size,self.hidden_size)\n",
    "                altx=cls_output\n",
    "                altx = self.classifier2(altx)\n",
    "                altx=self.personalization_layer(altx)\n",
    "\n",
    "                loss_1,logits,logits_list_test = criteria(sent, altx, label )\n",
    "                logits_list.append(logits_list_test)\n",
    "                loss = loss_1\n",
    "            \n",
    "        elif all_abb_bert: # when vectors from ABB_BERT is present\n",
    "            for num,(all_alt_abb_bert_vector,label) in enumerate(all_alt_abb_bert_vectors):\n",
    "                shapes_alts=all_alt_abb_bert_vector.shape\n",
    "                altx=all_alt_abb_bert_vector\n",
    "                criteria = AdMSoftmaxLoss(self.hidden_size,self.hidden_size)\n",
    "                altx=self.personalization_layer(altx)\n",
    "                print('altx shape',altx.shape)\n",
    "                print('sent shape',sent[num].shape)\n",
    "                loss,logits,logits_list_test = criteria(sent[num], altx, label)\n",
    "                print('numerator',logits_list_test.shape)\n",
    "                logits_list.append(logits_list_test)\n",
    "                \n",
    "        else:\n",
    "            pass\n",
    "            \n",
    "        return (loss), logits_list, logits_list_test,sent,sent_int2  # (loss), logits, (hidden_states), (attentions)\n",
    "\n",
    "model = BertForSequenceClassification_notes.from_pretrained('bert-base-uncased', num_labels=2)\n",
    "device = torch.device(\"cpu\")\n",
    "model.load_state_dict(torch.load(\"model/570000\",map_location=torch.device('cpu') ))\n",
    "model = model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "files_list = [l for l in os.listdir('dataset/') if 'test_' in l]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "N/A% (0 of 1000) |                       | Elapsed Time: 0:00:00 ETA:  --:--:--"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        ################################\n",
      "        ##### running validation #######\n",
      "        ################################\n",
      "        \n",
      "valid alt_size torch.Size([50, 8])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/share/cds/AI_DEMO/envs/apex_env/lib/python3.7/site-packages/ipykernel_launcher.py:83: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\r",
      "  0% (1 of 1000) |                       | Elapsed Time: 0:00:00 ETA:   0:06:12"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "valid alt_size torch.Size([100, 13])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-69c04754d715>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     85\u001b[0m                             \u001b[0mattention_mask_alt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb_input_mask_alt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m                             \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mb_labels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m                             \u001b[0mnum_of_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_of_options_val\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m                            )\n\u001b[1;32m     89\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/share/cds/AI_DEMO/envs/apex_env/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-a07bd12b165c>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, input_ids_alt, attention_mask, attention_mask_alt, token_type_ids, position_ids, head_mask, inputs_embeds, labels, train, index_of_abb, num_of_options, alt_batch, all_options, all_alt_input_ids, all_abb_bert, just_cls, all_alt_input_ids_vectors, all_alt_abb_bert_vectors)\u001b[0m\n\u001b[1;32m    162\u001b[0m                     \u001b[0mposition_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mposition_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m                     \u001b[0mhead_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhead_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m                     inputs_embeds=inputs_embeds)\n\u001b[0m\u001b[1;32m    165\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0malt_ids_index\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m                     \u001b[0mcls_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutputs_2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/share/cds/AI_DEMO/envs/apex_env/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    851\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    852\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 853\u001b[0;31m             \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    854\u001b[0m         )\n\u001b[1;32m    855\u001b[0m         \u001b[0msequence_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/share/cds/AI_DEMO/envs/apex_env/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    486\u001b[0m                     \u001b[0mencoder_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    487\u001b[0m                     \u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 488\u001b[0;31m                     \u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    489\u001b[0m                 )\n\u001b[1;32m    490\u001b[0m             \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/share/cds/AI_DEMO/envs/apex_env/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, output_attentions)\u001b[0m\n\u001b[1;32m    405\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m             \u001b[0mhead_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m         )\n\u001b[1;32m    409\u001b[0m         \u001b[0mattention_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself_attention_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/share/cds/AI_DEMO/envs/apex_env/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, output_attentions)\u001b[0m\n\u001b[1;32m    342\u001b[0m             \u001b[0mencoder_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m             \u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 344\u001b[0;31m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    345\u001b[0m         )\n\u001b[1;32m    346\u001b[0m         \u001b[0mattention_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/share/cds/AI_DEMO/envs/apex_env/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, output_attentions)\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m             \u001b[0mmixed_key_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 256\u001b[0;31m             \u001b[0mmixed_value_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m         \u001b[0mquery_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose_for_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmixed_query_layer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/share/cds/AI_DEMO/envs/apex_env/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/share/cds/AI_DEMO/envs/apex_env/lib/python3.7/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/share/cds/AI_DEMO/envs/apex_env/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1690\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1691\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1692\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1693\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1694\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Note: AdamW is a class from the huggingface library (as opposed to pytorch) \n",
    "# I believe the 'W' stands for 'Weight Decay fix\"\n",
    "import progressbar\n",
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr = 5e-6, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
    "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
    "                )\n",
    "\n",
    "# Number of training epochs (authors recommend between 2 and 4)\n",
    "epochs = 1\n",
    "\n",
    "\n",
    "import random\n",
    "\n",
    "seed_val = 42\n",
    "    \n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)\n",
    "\n",
    "# Store the average loss after each epoch so we can plot them.\n",
    "loss_values = []\n",
    "\n",
    "loss_values_x_batch = []\n",
    "loss_values_x_batch_means = []\n",
    "logs_diff_values_x_batch = []\n",
    "logs_diff_values_x_batch_means = []\n",
    "ratio_less_10 = []\n",
    "ratio_less_50 = []\n",
    "ratio_less_100 =[]\n",
    "\n",
    "val_rank_list = []\n",
    "rank_list=[]\n",
    "\n",
    "logs_diff_values_validate = []\n",
    "correct_rank_validate = []\n",
    "num_of_options_val=50\n",
    "num_of_options_train=50\n",
    "logs_diff_values_x_batch_validate = []\n",
    "correct_rank_val = []\n",
    "\n",
    "# For each epoch...\n",
    "step=0\n",
    "\n",
    "for epoch_i in range(0, epochs):\n",
    "    with writer.as_default():\n",
    "        tf.summary.scalar('epoch', epoch_i,step)\n",
    "\n",
    "    # Measure how long the training epoch takes.\n",
    "    t0 = time.time()\n",
    "\n",
    "    # Reset the total loss for this epoch.\n",
    "    total_loss = 0\n",
    "\n",
    "    model.train()\n",
    "\n",
    "#     # For each batch of training data...\n",
    "    for file_index, file in enumerate(files_list):\n",
    "        val_df = pickle.load(open('dataset/'+file, 'rb'))        \n",
    "        total_steps = len(val_df) * epochs\n",
    "        print('''\n",
    "        ################################\n",
    "        ##### running validation #######\n",
    "        ################################\n",
    "        ''')\n",
    "        total_steps = len(val_df) * epochs\n",
    "        for _, ind in enumerate(progressbar.progressbar(np.random.choice(len(val_df), len(val_df), replace=False))):\n",
    "            \n",
    "            step+=1\n",
    "            batch = val_df[ind][0],val_df[ind][1]\n",
    "            batch_alt = val_df[ind][2],val_df[ind][3] \n",
    "            print(\"valid alt_size\", batch_alt[0].shape)\n",
    "            b_input_ids = batch[0].to(device)\n",
    "            b_input_mask = batch[1].to(device)\n",
    "            b_input_ids_alt = batch_alt[0].to(device)\n",
    "            b_input_mask_alt = batch_alt[1].to(device)\n",
    "            b_labels = torch.zeros((num_of_options_val), dtype=torch.float).to(device)\n",
    "\n",
    "            model.eval()\n",
    "            outputs = model(input_ids = b_input_ids,\n",
    "                            input_ids_alt = b_input_ids_alt,\n",
    "                            token_type_ids=None, \n",
    "                            attention_mask=b_input_mask, \n",
    "                            attention_mask_alt = b_input_mask_alt,\n",
    "                            labels=b_labels,\n",
    "                            num_of_options=num_of_options_val\n",
    "                           )\n",
    "            model.zero_grad()\n",
    "            logs = outputs[2]\n",
    "            logs_diff_values_x_batch_validate.extend([g.item() for l in logs for g in [l[0] - torch.mean(l[1:])] ])\n",
    "\n",
    "            for predictions in logs:\n",
    "                sorted_pred = torch.sort(predictions, descending = True).indices.tolist()\n",
    "                correct_rank = sorted_pred.index(0)\n",
    "                print(correct_rank)\n",
    "                correct_rank_val.append(correct_rank)\n",
    "\n",
    "            with writer.as_default():\n",
    "                tf.summary.scalar('validation mean rank',np.mean(correct_rank_val),step)\n",
    "                tf.summary.scalar('validation log diff validation',np.mean(logs_diff_values_x_batch_validate),step)\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"Validation complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:AI_DEMO-apex_env] *",
   "language": "python",
   "name": "conda-env-AI_DEMO-apex_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
